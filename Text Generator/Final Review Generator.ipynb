{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to have the text because I need the source sequences as an input for the model to generate new sequences\n",
    "def load_reviews(text):\n",
    "    # open files read only\n",
    "    file = open(text, 'r')\n",
    "    \n",
    "    # read the file\n",
    "    text = file.read()\n",
    "    \n",
    "    # close the file\n",
    "    file.close()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With the base data and model loaded, it's time to generate text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no breads baguettes etc that offers'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The LSTM Model finally had a strong output which, if you only consider it a few words at a time, makes sense. However, as a whole, the review does not make sense, but it is progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user():\n",
    "    answer = False\n",
    "    while answer == False:\n",
    "        rating = input(\"What rating do you want to generate a review for? \\nPlease enter 'One', 'Two', 'Three', 'Four', 'Five'\\n\\n\")\n",
    "        rating = rating.title()\n",
    "        if rating == 'One':\n",
    "            doc = load_reviews('../NLP/One_Star.txt')\n",
    "            lines = doc.split('\\n')\n",
    "            seq_length = len(lines[0].split()) - 1\n",
    "            model = load_model('Models/model_1_star.h5')\n",
    "            tokenizer = load(open('Models/tokenizer_1_star.pkl', 'rb'))\n",
    "            \n",
    "            words = int(input('\\nHow many words would you like your review to be?\\n\\n'))\n",
    "            seed_text = lines[randint(0, len(lines))]\n",
    "            generated = generate_seq(model, tokenizer, seq_length, seed_text, words)\n",
    "            answer = True\n",
    "            return (generated)\n",
    "            \n",
    "        \n",
    "        if rating == 'Two':\n",
    "            doc = load_reviews('../NLP/Two_Star.txt')\n",
    "            lines = doc.split('\\n')\n",
    "            seq_length = len(lines[0].split()) - 1\n",
    "            model = load_model('Models/model_two_star.h5')\n",
    "            tokenizer = load(open('Models/tokenizer_2_star.pkl', 'rb'))\n",
    "            \n",
    "            words = int(input('\\nHow many words would you like your review to be?\\n\\n'))\n",
    "            seed_text = lines[randint(0, len(lines))]\n",
    "            generated = generate_seq(model, tokenizer, seq_length, seed_text, words)\n",
    "            answer = True\n",
    "            return (generated)\n",
    "       \n",
    "        if rating == 'Three':\n",
    "            doc = load_reviews('../NLP/Three_Star.txt')\n",
    "            lines = doc.split('\\n')\n",
    "            seq_length = len(lines[0].split()) - 1\n",
    "            model = load_model('Models/model_three_star.h5')\n",
    "            tokenizer = load(open('Models/tokenizer_3_star.pkl', 'rb'))\n",
    "            \n",
    "            words = int(input('\\nHow many words would you like your review to be?\\n\\n'))\n",
    "            seed_text = lines[randint(0, len(lines))]\n",
    "            generated = generate_seq(model, tokenizer, seq_length, seed_text, words)\n",
    "            answer = True\n",
    "            return (generated)\n",
    "        \n",
    "        if rating == 'Four':\n",
    "            doc = load_reviews('../NLP/Four_Star.txt')\n",
    "            lines = doc.split('\\n')\n",
    "            seq_length = len(lines[0].split()) - 1\n",
    "            model = load_model('Models/final_model_4.h5')\n",
    "            tokenizer = load(open('Models/final_tokenizer_4.pkl', 'rb'))\n",
    "            \n",
    "            words = int(input('\\nHow many words would you like your review to be?\\n\\n'))\n",
    "            seed_text = lines[randint(0, len(lines))]\n",
    "            generated = generate_seq(model, tokenizer, seq_length, seed_text, words)\n",
    "            answer = True\n",
    "            print('Seed text to generate review: ' + seed_text)\n",
    "            return (generated)\n",
    "        \n",
    "        if rating == 'Five':\n",
    "            doc = load_reviews('../NLP/Five_Star.txt')\n",
    "            lines = doc.split('\\n')\n",
    "            seq_length = len(lines[0].split()) - 1\n",
    "            model = load_model('Models/model_five_star.h5')\n",
    "            tokenizer = load(open('Models/tokenizer_5_star.pkl', 'rb'))\n",
    "            \n",
    "            words = int(input('\\nHow many words would you like your review to be?\\n\\n'))\n",
    "            seed_text = lines[randint(0, len(lines))]\n",
    "            generated = generate_seq(model, tokenizer, seq_length, seed_text, words)\n",
    "            answer = True\n",
    "            print(seed_text)\n",
    "            return (generated)            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Text Generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simply enter the rating you want to give as well as the number of words you would like your review to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What rating do you want to generate a review for? \n",
      "Please enter 'One', 'Two', 'Three', 'Four', 'Five'\n",
      "\n",
      "Two\n",
      "\n",
      "How many words would you like your review to be?\n",
      "\n",
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'only way i were a little wreck and the only shared steak sandwich and a good and release than the service and i think it was a few airconditioning begins to the only shared roasted beets and character sounded than the food of the only admitted i were not been'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
