{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('1_Rating.csv')\n",
    "df2 = pd.read_csv('2_Rating.csv')\n",
    "df3 = pd.read_csv('3_Rating.csv')\n",
    "df4 = pd.read_csv('4_Rating.csv')\n",
    "df5 = pd.read_csv('5_Rating.csv')\n",
    "\n",
    "df1.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df2.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df3.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df4.drop(columns=['Unnamed: 0'], inplace = True)\n",
    "df5.drop(columns=['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_star_reviews = df1['Text'].tolist()\n",
    "two_star_reviews = df2['Text'].tolist()\n",
    "three_star_reviews = df3['Text'].tolist()\n",
    "four_star_reviews = df4['Text'].tolist()\n",
    "five_star_reviews = df5['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Sugar Factory is known for it\\'s delicious drinks and some of the worst service in town.\\n\\nSeriously, I\\'ve had a problem with the Sugar Factory on the strip with customer service, and after visiting this location for the first time the other day, my hopes of better service crumbled, it\\'s even worse here.\\n\\nWhile the hostess was great and quick about seating us, we sat there for about 12 minutes before anyone even came over. Not only was the waitress slow, she seemed confused as to what tables she was suppose to be waiting. A moment after she left, another waiter came to take our order once again, and was confused that we had ordered with someone else already.\\n\\nI usually get the veggie burger from Sugar Factory, not only is it really the only acceptable vegetarian dish on the menu, it\\'s just delicious. I don\\'t know whether they changed the recipe or the chef is an idiot, but the once signature purple bun was replaced with a regular white bun. Bummer. :(\\n\\nFinishing touch to our horrible experience, the bartender that brought us our drinks was a complete bitch. We sat by the bar so I could see what they were doing. She was chatting with another bartender and seemed irritated that she had to work, you know, do her job, and make drinks. When she brought over the drinks you could tell she was in such a pissy mood because she couldn\\'t concentrate enough to hold the drinks steady, she spilled a good portion of mine all over her hand and slammed the drinks on the table (further spilling my Cherry Pop drink) So now I have a drink with 1/2\" of it spilled all over the table and she stomps off without an apology or cleaning up her mess. \\n\\nAlso, sticking the cherry tootsie pop in the drink is a great idea and all. But it would be better if they took the wrapper off and put the sucker in handle-up.More pleasant to hold and no one has to peel the wet paper off the candy. \\n\\nAs good as their sugary sweets are, the service and prices are enough to sour our mood. Stay away. FARRRR AWAYYYYYYY'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_star_reviews[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to clean up the text in the reviews as I tokenize so my generator doesn't produce something like '\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanin_reviews(review):\n",
    "    # Many reviews have \\n characters through my scrape, so I need to replace those with empty spaces\n",
    "    review = review.replace('\\n\\n', ' ')\n",
    "    # Splitting on spaces to tokenize\n",
    "    tokens = review.split()\n",
    "    # Getting rid of punctuation because 'word.' will be considered different from 'word'\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [word.translate(table) for word in tokens]\n",
    "    # Simplifying my vocabulary to only include words and not smiley faces/other datatypes\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(star):\n",
    "    all_tokens = []\n",
    "\n",
    "    for reviews in star:\n",
    "        all_tokens.append(cleanin_reviews(reviews))\n",
    "    \n",
    "    # The above makes a list of lists, but I need to have one giant list of tokens\n",
    "    flat_list = [item for sublist in all_tokens for item in sublist]\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_stars = tokenizer(one_star_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1370411\n",
      "Unique Tokens: 37674\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(one_stars))\n",
    "print('Unique Tokens: %d' % len(set(one_stars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_stars = tokenizer(two_star_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 1485599\n",
      "Unique Tokens: 40776\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(two_stars))\n",
    "print('Unique Tokens: %d' % len(set(two_stars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three Star Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_stars = tokenizer(three_star_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 3181354\n",
      "Unique Tokens: 61030\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(three_stars))\n",
    "print('Unique Tokens: %d' % len(set(three_stars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Star Reviews\n",
    "\n",
    "The lower total tokens count represents the smaller datasets for the review set. If the model ends up not being as robust as the others, I will obtain additional datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_stars = tokenizer(four_star_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 489058\n",
      "Unique Tokens: 30313\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(four_stars))\n",
    "print('Unique Tokens: %d' % len(set(four_stars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Star Reviews\n",
    "\n",
    "The lower total tokens count represents the smaller datasets for the review set. If the model ends up not being as robust as the others, I will obtain additional datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_stars = tokenizer(five_star_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 670280\n",
      "Unique Tokens: 37641\n"
     ]
    }
   ],
   "source": [
    "print('Total Tokens: %d' % len(five_stars))\n",
    "print('Unique Tokens: %d' % len(set(five_stars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_of_tokens(stars):\n",
    "    length = 5 + 1\n",
    "    sequences = list()\n",
    "    for i in range(length, len(stars)):\n",
    "        seq = stars[i-length:i]\n",
    "\n",
    "        line = ' '.join(seq)\n",
    "\n",
    "        sequences.append(line)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 1370405\n"
     ]
    }
   ],
   "source": [
    "one_star = sequence_of_tokens(one_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 1485593\n"
     ]
    }
   ],
   "source": [
    "two_star = sequence_of_tokens(two_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 3181348\n"
     ]
    }
   ],
   "source": [
    "three_star = sequence_of_tokens(three_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 489052\n"
     ]
    }
   ],
   "source": [
    "four_star = sequence_of_tokens(four_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 670274\n"
     ]
    }
   ],
   "source": [
    "five_star = sequence_of_tokens(five_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to save these different sequences down to train my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saver(lines, name):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(name, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver(one_star, 'One_Star.txt')\n",
    "saver(two_star, 'Two_Star.txt')\n",
    "saver(three_star, 'Three_star.txt')\n",
    "saver(four_star, 'Four_Star.txt')\n",
    "saver(five_star, 'Five_Star.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
