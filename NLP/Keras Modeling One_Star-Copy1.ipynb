{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries to run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to load my 5 txt files to make the 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(textfile):\n",
    "    # Open the file as read-only\n",
    "    file = open(textfile, 'r')\n",
    "    # Actually read the file\n",
    "    text = file.read()\n",
    "    # Now that I have the data in my text variable, need to close out of the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 5 instances of the 5 ratings\n",
    "\n",
    "one = loader('One_Star.txt')\n",
    "# two = loader('Two_Star.txt')\n",
    "# three = loader('Three_Star.txt')\n",
    "# four = loader('Four_Star.txt')\n",
    "# five = loader('Five_Star.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to split up each of these data sets into training sequences by the different lines. \n",
    "# End goal is to have user input 5 words and the text generator will work its magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_lines = one.split('\\n')\n",
    "# two_lines = two.split('\\n')\n",
    "# three_lines = three.split('\\n')\n",
    "# four_lines = four.split('\\n')/\n",
    "# five_lines = five.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atrocious the live music was loud',\n",
       " 'the live music was loud and',\n",
       " 'live music was loud and mediocre',\n",
       " 'music was loud and mediocre the',\n",
       " 'was loud and mediocre the decor']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each line has been broken out with 5 sequence of words\n",
    "one_lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to convert the words in my data to integers in order to be used by the model. \n",
    "\n",
    "Will need to train the keras tokenizer on entire dataset to assign a unique ID to each unique word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "def word_to_int(lines):\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    sequences = tokenizer.texts_to_sequences(one_lines)\n",
    "    # Need the total size of the vocabulary for our embedding layer in model\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return sequences, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the function for all 5 data sets\n",
    "one_sequence, one_vocab_size = word_to_int(one_lines)\n",
    "# two_sequence, two_vocab_size = word_to_int(two_lines)\n",
    "# three_sequence, three_vocab_size = word_to_int(three_lines)\n",
    "# four_sequence, four_vocab_size = word_to_int(four_lines)\n",
    "# five_sequence, five_vocab_size = word_to_int(five_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each line has been converted to unique ints to represent each word\n",
    "len(one_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_one = one_sequence[0:200000]\n",
    "\n",
    "part_two = one_sequence[200001:400000]\n",
    "\n",
    "part_three = one_sequence[400001:600000]\n",
    "\n",
    "part_four = one_sequence[600001:800000]\n",
    "\n",
    "part_five = one_sequence[800001:1000000]\n",
    "\n",
    "part_six = one_sequence[1000001:1200000]\n",
    "\n",
    "part_seven = one_sequence[1200001:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need to convert my sequences into inputs and outputs to structure my model to predict words based on previous set of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Star Review Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sequences = np.array(one_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2374,     1,   551,   549,     7,   809],\n",
       "       [    1,   551,   549,     7,   809,     3],\n",
       "       [  551,   549,     7,   809,     3,  1044],\n",
       "       ...,\n",
       "       [ 5128,  4040,   284,    32,  2091, 12323],\n",
       "       [ 4040,   284,    32,  2091, 12323,     8],\n",
       "       [  284,    32,  2091, 12323,     8,    15]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-e61026689413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "X, y = one_sequence[:,:-1], one_sequence[:,-1]\n",
    "y = to_categorical(y, num_classes=one_vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/hiowatah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 5, 50)             1883750   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 25)             7600      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25)                5100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 37675)             979550    \n",
      "=================================================================\n",
      "Total params: 2,876,650\n",
      "Trainable params: 2,876,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# defining my model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(one_vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(25, return_sequences=True))\n",
    "model.add(LSTM(25))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(one_vocab_size, activation = 'softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1370405/1370405 [==============================] - 1501s 1ms/step - loss: 6.3984 - acc: 0.0792\n",
      "Epoch 2/25\n",
      "1370405/1370405 [==============================] - 1549s 1ms/step - loss: 5.9729 - acc: 0.1117\n",
      "Epoch 3/25\n",
      "1370405/1370405 [==============================] - 1619s 1ms/step - loss: 5.8094 - acc: 0.1222\n",
      "Epoch 4/25\n",
      "1370405/1370405 [==============================] - 1648s 1ms/step - loss: 5.6973 - acc: 0.1293\n",
      "Epoch 5/25\n",
      "1370405/1370405 [==============================] - 1647s 1ms/step - loss: 5.6134 - acc: 0.1345\n",
      "Epoch 6/25\n",
      "1370405/1370405 [==============================] - 1683s 1ms/step - loss: 5.5464 - acc: 0.1389\n",
      "Epoch 7/25\n",
      "1370405/1370405 [==============================] - 1673s 1ms/step - loss: 5.4907 - acc: 0.1425\n",
      "Epoch 8/25\n",
      "1370405/1370405 [==============================] - 1666s 1ms/step - loss: 5.4425 - acc: 0.1460\n",
      "Epoch 9/25\n",
      "1370405/1370405 [==============================] - 1652s 1ms/step - loss: 5.4006 - acc: 0.1488\n",
      "Epoch 10/25\n",
      "1370405/1370405 [==============================] - 1653s 1ms/step - loss: 5.3625 - acc: 0.1515\n",
      "Epoch 11/25\n",
      "1370405/1370405 [==============================] - 1654s 1ms/step - loss: 5.3282 - acc: 0.1541\n",
      "Epoch 12/25\n",
      "1370405/1370405 [==============================] - 1657s 1ms/step - loss: 5.2966 - acc: 0.1563\n",
      "Epoch 13/25\n",
      "1370405/1370405 [==============================] - 1657s 1ms/step - loss: 5.2678 - acc: 0.1587\n",
      "Epoch 14/25\n",
      "1370405/1370405 [==============================] - 1654s 1ms/step - loss: 5.2404 - acc: 0.1609\n",
      "Epoch 15/25\n",
      "1370405/1370405 [==============================] - 1655s 1ms/step - loss: 5.2160 - acc: 0.1629\n",
      "Epoch 16/25\n",
      "1370405/1370405 [==============================] - 1655s 1ms/step - loss: 5.1926 - acc: 0.1649\n",
      "Epoch 17/25\n",
      "1370405/1370405 [==============================] - 1653s 1ms/step - loss: 5.1712 - acc: 0.1666\n",
      "Epoch 18/25\n",
      "1370405/1370405 [==============================] - 1655s 1ms/step - loss: 5.1514 - acc: 0.1683\n",
      "Epoch 19/25\n",
      "1370405/1370405 [==============================] - 1654s 1ms/step - loss: 5.1326 - acc: 0.1697\n",
      "Epoch 20/25\n",
      "1370405/1370405 [==============================] - 1648s 1ms/step - loss: 5.1148 - acc: 0.1714\n",
      "Epoch 21/25\n",
      "1370405/1370405 [==============================] - 1683s 1ms/step - loss: 5.0987 - acc: 0.1727\n",
      "Epoch 22/25\n",
      "1370405/1370405 [==============================] - 1687s 1ms/step - loss: 5.0833 - acc: 0.1739\n",
      "Epoch 23/25\n",
      "1370405/1370405 [==============================] - 1678s 1ms/step - loss: 5.0691 - acc: 0.1753\n",
      "Epoch 24/25\n",
      "1370405/1370405 [==============================] - 1695s 1ms/step - loss: 5.0550 - acc: 0.1763\n",
      "Epoch 25/25\n",
      "1370405/1370405 [==============================] - 1701s 1ms/step - loss: 5.0420 - acc: 0.1777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb337ecb70>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X,y,batch_size=256, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
